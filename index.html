<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8" />
  <title>Kalki Charan Kottapalli - Senior AI/ML Engineer</title>
  <style>
    body {
      font-family: Arial, Helvetica, sans-serif;
      background-color: #f5f5f5;
      margin: 0;
      padding: 0;
      color: #222;
    }

    .resume {
      max-width: 900px;
      margin: 30px auto;
      background-color: #ffffff;
      padding: 32px 40px;
      box-shadow: 0 0 12px rgba(0, 0, 0, 0.08);
      box-sizing: border-box;
    }

    h1 {
      font-size: 32px;
      margin: 0;
      letter-spacing: 0.03em;
      text-transform: uppercase;
    }

    h2 {
      font-size: 20px;
      margin-top: 24px;
      margin-bottom: 8px;
      border-bottom: 1px solid #ddd;
      padding-bottom: 4px;
      text-transform: uppercase;
      letter-spacing: 0.08em;
      font-weight: 600;
    }

    h3 {
      font-size: 16px;
      margin: 12px 0 4px;
      font-weight: 600;
    }

    p {
      margin: 4px 0 8px;
      line-height: 1.5;
      font-size: 14px;
    }

    .subtitle {
      font-size: 16px;
      margin-top: 4px;
      color: #555;
      font-weight: 500;
    }

    .contact {
      margin-top: 12px;
      font-size: 14px;
    }

    .contact span {
      display: inline-block;
      margin-right: 16px;
    }

    .section {
      margin-top: 20px;
    }

    .section-title {
      font-size: 18px;
      font-weight: 600;
      margin-bottom: 8px;
      text-transform: uppercase;
      letter-spacing: 0.09em;
      border-bottom: 2px solid #222;
      padding-bottom: 4px;
    }

    ul {
      margin-top: 4px;
      margin-bottom: 8px;
      padding-left: 20px;
    }

    li {
      margin-bottom: 4px;
      font-size: 14px;
      line-height: 1.5;
    }

    .job {
      margin-top: 16px;
    }

    .job-header {
      display: flex;
      justify-content: space-between;
      align-items: baseline;
      flex-wrap: wrap;
      gap: 4px;
    }

    .job-title {
      font-weight: 600;
      font-size: 15px;
    }

    .job-client {
      font-weight: 600;
      font-size: 14px;
    }

    .job-location {
      font-size: 13px;
      color: #555;
    }

    .job-dates {
      font-size: 13px;
      color: #555;
      text-align: right;
    }

    @media (max-width: 600px) {
      .resume {
        padding: 20px;
      }
      .job-header {
        flex-direction: column;
        align-items: flex-start;
      }
      .job-dates {
        text-align: left;
      }
    }
  </style>
</head>
<body>
  <div class="resume">
    <!-- Header -->
    <header>
      <h1>Kalki Charan Kottapalli</h1>
      <div class="subtitle">Senior AI/ML Engineer</div>
      <div class="contact">
        <span>Phone: (772) 202 - 1974</span>
        <span>Email: <a href="mailto:kalkicharandev@gmail.com">kalkicharandev@gmail.com</a></span>
      </div>
    </header>

    <!-- Professional Essence -->
    <section class="section">
      <div class="section-title">Professional Essence</div>
      <p>
        Senior AI/ML Engineer with 10+ years of experience architecting enterprise-scale, multi-cloud AI and data
        platforms to deliver scalable, automated and secure machine learning solutions and expert in managing the full ML
        lifecycle, including data engineering, model development, deployment and MLOps automation, to build intelligent,
        high-performance systems. Proven track record in designing explainable, reliable and production-grade AI
        solutions that accelerate enterprise innovation, operational efficiency and data-driven decision-making.
      </p>
    </section>

    <!-- Core Technical Strengths -->
    <section class="section">
      <div class="section-title">Core Skills & Expertise</div>

      <h3>AI/ML Architecture &amp; Model Development</h3>
      <ul>
        <li>Architected enterprise-scale, multi-cloud (AWS, Azure, GCP) AI and data platforms delivering automated, scalable and secure ML solutions.</li>
        <li>Designed and deployed end-to-end ML pipelines using SageMaker, Vertex AI and Azure ML, integrated with orchestration tools such as Airflow, Kubeflow and Prefect.</li>
        <li>Developed deep learning and generative AI applications, fine-tuning LLMs and applying advanced prompt engineering with Hugging Face, TensorFlow and PyTorch.</li>
      </ul>

      <h3>Data Engineering &amp; Feature Pipelines</h3>
      <ul>
        <li>Expertise in data ingestion and transformation using AWS Glue, Azure Data Factory, PySpark, DataProc, Dask, Pandas, NumPy, SQL and Delta Lake to deliver ML-ready datasets.</li>
        <li>Experienced in cloud-based data warehousing and analytics with BigQuery, Snowflake, AWS Redshift, Azure Synapse, Cloud SQL and Athena.</li>
        <li>Skilled in real-time and event-driven ML architectures using Kafka, Kinesis, Pub/Sub and Azure Stream Analytics, with Celery, Boto3 and BeautifulSoup for automated data extraction and feature generation.</li>
      </ul>

      <h3>MLOps, CI/CD &amp; Automation</h3>
      <ul>
        <li>Skilled in MLOps automation and CI/CD with Jenkins, GitHub Actions, Bitbucket, AWS CodePipeline and CodeBuild for reliable, version-controlled ML and data pipeline deployments.</li>
        <li>Strong background in infrastructure-as-code using Terraform, CloudFormation, ARM Templates and Google Cloud Deployment Manager to enable reproducible AI environments.</li>
        <li>Experienced in ML deployment and scaling using Docker, Kubernetes, Fargate, EKS, AKS and GKE, with automated monitoring via SageMaker Model Monitor, CloudWatch and Vertex AI Pipelines for drift detection and SLA compliance.</li>
      </ul>

      <h3>Data Management, Monitoring &amp; Observability</h3>
      <ul>
        <li>Strong understanding of data storage and feature stores including PostgreSQL, MongoDB, Redis, MySQL, Oracle and SQL Server, focusing on schema optimization, versioning and data lineage.</li>
        <li>Experienced in visualization, monitoring and model observability using Grafana, Prometheus, Cloud Logging, AWS QuickSight, Power BI, Tableau, Looker and Matplotlib, ensuring insight-driven AI operations.</li>
        <li>Implemented data validation and quality checks with Great Expectations and built interpretable ML solutions leveraging OpenCV, NumPy and Matplotlib for explainability and visualization.</li>
        <li>Managed and secured ML infrastructure across EC2, EFS, FSx, VPC, IAM, Azure VMs and GCE, ensuring fault tolerance, governance and cost efficiency.</li>
      </ul>

      <h3>Experimentation, Testing &amp; Reliability</h3>
      <ul>
        <li>Experienced in experiment tracking, model management and versioning with MLflow, DVC, TensorBoard, Weights &amp; Biases (W&amp;B) and SageMaker Model Registry for reproducible and auditable ML operations.</li>
        <li>Skilled in testing and optimizing ML systems using Pytest, unittest and Jupyter Notebook to enhance robustness, maintainability and experimentation efficiency.</li>
        <li>Delivered scalable, explainable AI systems integrating MLOps, DevOps and LLM technologies to accelerate enterprise adoption of intelligent, high-performance data solutions.</li>
      </ul>
    </section>

    <!-- Professional Experience -->
    <section class="section">
      <div class="section-title">Professional Experience</div>

      <!-- B. Riley Financial -->
      <div class="job">
        <div class="job-header">
          <div>
            <div class="job-title">Senior AI/ML Engineer</div>
            <div class="job-client">Client: B. Riley Financial</div>
            <div class="job-location">Los Angeles, CA</div>
          </div>
          <div class="job-dates">Duration: March 2024 - Present</div>
        </div>
        <ul>
          <li>Architected and maintained scalable, end-to-end AI/ML data pipelines using Cloud Data Flow, Vertex AI and DataProc, enabling automated model training, evaluation and retraining across cloud environments.</li>
          <li>Designed and optimized data ingestion and transformation frameworks leveraging PyODBC, BigQuery and Pandas, delivering high-quality, ML-ready datasets to support advanced analytics and forecasting models.</li>
          <li>Engineered feature stores and low-latency NoSQL data layers with MongoDB and Redis, streamlining real-time feature retrieval and accelerating inference performance for AI-driven products.</li>
          <li>Built and deployed secure, high-performance APIs using FastAPI and Flask, serving model predictions and powering intelligent microservice-based architectures.</li>
          <li>Developed real-time streaming and event-driven data pipelines using Apache Kafka, Pub/Sub and Dataflow, enabling dynamic feature updates and continuous online model learning.</li>
          <li>Created distributed data processing and large-scale training pipelines with PySpark, DataProc and Dask, achieving 10x improvements in processing efficiency for terabyte-scale ML datasets.</li>
          <li>Designed and orchestrated robust MLOps pipelines using Vertex AI Pipelines, Kubeflow and MLflow, automating experiment tracking, versioning and model deployment.</li>
          <li>Built, trained and optimized machine learning and deep learning models using TensorFlow, PyTorch, Keras and Scikit-learn, improving prediction accuracy and reducing training time.</li>
          <li>Automated cloud infrastructure provisioning through Google Cloud Deployment Manager and Terraform, establishing reproducible, version-controlled and compliant AI environments.</li>
          <li>Implemented continuous integration and deployment automation for ML workflows using GitHub Actions, Jenkins and Docker, reducing model deployment latency by 40%.</li>
          <li>Containerized and deployed scalable AI/ML services on Kubernetes (GKE) and Cloud Run, ensuring fault tolerance, automatic scaling and efficient resource utilization.</li>
          <li>Partnered with data scientists to productionize models with Vertex AI, integrating model drift detection, A/B testing and automated retraining to maintain model reliability.</li>
          <li>Applied prompt engineering techniques and leveraged Hugging Face Transformers to fine-tune LLMs, enhancing contextual understanding and domain-specific response accuracy.</li>
          <li>Utilized BigQuery ML and AutoML to streamline experimentation and rapidly prototype predictive models with minimal manual intervention.</li>
          <li>Designed modular, version-controlled orchestration workflows using Dagster and Apache Airflow, ensuring visibility, traceability and reliability across end-to-end ML pipelines.</li>
          <li>Implemented data and model versioning using DVC and MLflow, enabling full experiment reproducibility and maintaining lineage across model life cycles.</li>
          <li>Optimized large-scale data transformations and training processes using NumPy, Spark SQL and TensorBoard, driving efficient model convergence and resource optimization.</li>
          <li>Leveraged core Google Cloud services including GCE, Cloud Storage, Filestore and IAM to ensure data security, governance and cost efficiency for AI workloads.</li>
          <li>Built proactive observability and monitoring systems using Prometheus, Grafana and Cloud Logging, enabling real-time visibility into pipeline health and model performance metrics.</li>
          <li>Enabled enterprise-scale intelligent decision systems by integrating MLOps, LLM technologies and cloud-native AI infrastructure, accelerating the deployment of explainable, scalable AI solutions.</li>
        </ul>
      </div>

      <!-- Discover -->
      <div class="job">
        <div class="job-header">
          <div>
            <div class="job-title">Senior AI/ML Engineer</div>
            <div class="job-client">Client: Discover</div>
            <div class="job-location">Riverwoods, IL</div>
          </div>
          <div class="job-dates">Duration: Sep 2021 - Jan 2024</div>
        </div>
        <ul>
          <li>Architected metadata-driven, reusable ML data pipelines using AWS Glue and SageMaker Feature Store, automating feature discovery and versioning to cut data preparation time by 60%.</li>
          <li>Designed and orchestrated end-to-end MLOps workflows with AWS Step Functions and SageMaker Pipelines, enabling scalable, reproducible and secure training and deployment across environments.</li>
          <li>Engineered and deployed high-performance model-serving APIs using TensorFlow Serving and FastAPI, achieving ultra–low-latency inference and increasing model throughput by 40%.</li>
          <li>Designed and implemented scalable, distributed feature computation and analytics pipelines with AWS Athena, PySpark and Amazon S3, delivering real-time insights that improved data-driven decision-making.</li>
          <li>Standardized and automated experiment tracking and model versioning using MLflow and Weights &amp; Biases (W&amp;B), enhancing reproducibility, traceability and compliance across model lifecycles.</li>
          <li>Developed and orchestrated event-driven ML retraining and inference workflows leveraging AWS Lambda and Amazon SQS, automating triggers and reducing manual intervention by 90%.</li>
          <li>Built and maintained streaming data ingestion and online inference systems using Amazon Kinesis and Kafka Streams, achieving sub-second latency for real-time analytics applications.</li>
          <li>Optimized distributed training and hyperparameter tuning pipelines with Amazon SageMaker and Ray, improving GPU utilization and reducing training time by up to 80%.</li>
          <li>Containerized, orchestrated and deployed ML workloads using Docker and Amazon EKS, ensuring elastic scalability, fault tolerance and operational consistency across environments.</li>
          <li>Automated infrastructure provisioning and CI/CD workflows using Terraform and Jenkins, enabling version-controlled, auditable and fully reproducible ML environments.</li>
          <li>Integrated Amazon SageMaker Studio with enterprise CI/CD pipelines, accelerating model experimentation, reducing time-to-production and improving team productivity.</li>
          <li>Secured and monitored AI infrastructure on Amazon EC2 using AWS IAM and VPC policies, enforcing role-based access control (RBAC) and maintaining enterprise-grade compliance.</li>
          <li>Orchestrated and monitored DAG-based ML workflows using Apache Airflow and Prefect, enhancing pipeline reliability, observability and automated fault recovery.</li>
          <li>Developed end-to-end CI/CD pipelines with AWS CodePipeline and GitHub Actions, automating testing, packaging and deployment for ML models and related artifacts.</li>
          <li>Enforced comprehensive data validation with Great Expectations, improving data quality and preventing model performance regressions across training and inference stages.</li>
          <li>Implemented real-time model drift detection and monitoring using Prometheus and SageMaker Model Monitor, ensuring SLA adherence and production model reliability.</li>
          <li>Delivered scalable AI/ML solutions using Python and TensorFlow, applying deep learning and classical machine learning techniques to solve high-impact business problems.</li>
          <li>Leveraged Pandas, NumPy and Matplotlib for efficient data preprocessing, automation and visualization, enhancing model interpretability and transparency.</li>
        </ul>
      </div>

      <!-- Baxter International -->
      <div class="job">
        <div class="job-header">
          <div>
            <div class="job-title">ML Engineer</div>
            <div class="job-client">Client: Baxter International</div>
            <div class="job-location">Deerfield, IL</div>
          </div>
          <div class="job-dates">Duration: Jul 2019 - Sep 2021</div>
        </div>
        <ul>
          <li>Architected and maintained scalable ML pipelines using Azure Machine Learning and Azure Data Factory, improving model training and deployment efficiency by 40% across enterprise environments.</li>
          <li>Led enhancements to MLOps workflows within Azure Machine Learning and MLflow, enabling real-time model retraining and deployment across hybrid systems, improving reliability and speed of AI-driven analytics.</li>
          <li>Designed and deployed production-ready inference APIs using FastAPI and GraphQL, improving model serving flexibility and reducing response latency by 30%, enabling faster decision-making through AI-enabled dashboards.</li>
          <li>Developed and scaled a cloud-based feature store and model registry on Azure Synapse Analytics and Azure Machine Learning, supporting multi-terabyte datasets and enabling sub-second feature retrieval for model scoring.</li>
          <li>Administered and optimized training databases on Azure Database for PostgreSQL and MySQL, ensuring 99.99% uptime and fast data access for model input and experiment tracking.</li>
          <li>Built real-time model inference pipelines using Azure Event Hub and Kafka, processing millions of telemetry events per hour to power predictive analytics and anomaly detection with minimal latency.</li>
          <li>Engineered low-latency model serving systems with Azure Service Bus and Kubernetes, enabling asynchronous, scalable inference across distributed microservices for high-throughput analytics workloads.</li>
          <li>Delivered big data–driven model training pipelines using Azure HDInsight, Spark MLlib and Hadoop, enabling large-scale parallel training and hyperparameter tuning across multi-gigabyte datasets.</li>
          <li>Deployed containerized ML workloads using Docker and Azure Kubernetes Service (AKS), streamlining experimentation-to-production transitions and minimizing deployment overhead.</li>
          <li>Automated ML infrastructure provisioning and pipeline orchestration using Terraform and Azure Resource Manager (ARM) templates, reducing setup times and deployment errors by 70% via infrastructure-as-code.</li>
          <li>Collaborated with data scientists to productionize and optimize machine learning models in TensorFlow, PyTorch and Scikit-learn, integrating real-time inference and feedback loops for personalization and anomaly detection.</li>
          <li>Leveraged core Azure cloud services including Azure Virtual Machines, Blob Storage, Azure Files and VPN Gateway to support secure model training, high-volume data storage and hybrid ML workflows across environments.</li>
          <li>Orchestrated complex ML DAGs and retraining workflows using Apache Airflow and Kubeflow Pipelines, improving workflow visibility and reliability while reducing manual intervention.</li>
          <li>Enabled continuous integration and deployment (CI/CD) for ML models using Bitbucket, GitHub Actions and MLflow, automating testing, version control and model rollouts for faster and more reliable releases.</li>
          <li>Engineered data preprocessing and feature engineering pipelines in Python using Pandas, NumPy and Scikit-learn, enabling large-scale data cleansing, transformation and analysis to enhance model accuracy.</li>
        </ul>
      </div>

      <!-- ACNB Bank -->
      <div class="job">
        <div class="job-header">
          <div>
            <div class="job-title">ML Engineer</div>
            <div class="job-client">Client: ACNB Bank</div>
            <div class="job-location">Gettysburg, PA</div>
          </div>
          <div class="job-dates">Duration: Apr 2017 - Jun 2019</div>
        </div>
        <ul>
          <li>Designed and maintained scalable data pipelines and feature stores using AWS Glue Catalog and Amazon SageMaker, enabling efficient schema management and feature discovery for ML models.</li>
          <li>Built and automated model training and inference pipelines using AWS SageMaker and Apache Airflow, orchestrating end-to-end workflows for data preparation, training, evaluation and deployment.</li>
          <li>Developed and optimized SQL and PySpark transformations to prepare large-scale datasets for model training and validation, leveraging Databricks for distributed data processing.</li>
          <li>Designed and deployed RESTful model inference APIs using Flask, implementing token-based authentication and containerization with Docker for secure, scalable model serving across production environments.</li>
          <li>Developed interactive ML monitoring dashboards using AWS QuickSight and Grafana, integrating with model metrics such as latency, accuracy drift and data quality to improve model observability and decision-making speed.</li>
          <li>Architected and optimized model storage and versioning systems on AWS S3 and MLflow, enabling experiment tracking, reproducibility and auditability for large-scale machine learning projects.</li>
          <li>Built and orchestrated MLOps pipelines using Apache Airflow and Jenkins, automating retraining, validation and CI/CD for ML models across staging and production environments.</li>
          <li>Implemented real-time model inference pipelines using Apache Kafka and TensorFlow Serving, enabling low-latency predictions for streaming data and real-time anomaly detection systems.</li>
          <li>Leveraged PyTorch, TensorFlow and Scikit-learn for developing and training deep learning and traditional machine learning models, incorporating feature engineering, model tuning and evaluation for production efficiency.</li>
          <li>Developed and deployed machine learning models using Scikit-learn, XGBoost and LightGBM, integrating automated feature engineering, model evaluation and A/B testing into data pipelines for predictive analytics.</li>
          <li>Configured and secured cloud ML infrastructure using AWS VPC, IAM, Internet Gateway and NAT Gateway, ensuring secure access for training workloads and API-based model inference.</li>
          <li>Designed and implemented end-to-end ML orchestration with Apache Airflow, including data ingestion, preprocessing, model retraining and deployment monitoring workflows for production-grade AI systems.</li>
          <li>Integrated CI/CD workflows for ML using Jenkins, Git and Docker, enabling automated model testing, deployment and version control for reproducible ML codebases.</li>
          <li>Developed and tested ML applications in Python, utilizing libraries such as Pytest for unit testing, MLflow for model tracking and Scikit-learn for model experimentation and evaluation.</li>
        </ul>
      </div>

      <!-- Trupanion -->
      <div class="job">
        <div class="job-header">
          <div>
            <div class="job-title">Data Engineer</div>
            <div class="job-client">Client: Trupanion</div>
            <div class="job-location">Seattle, WA</div>
          </div>
          <div class="job-dates">Duration: Jan 2014 - Mar 2017</div>
        </div>
        <ul>
          <li>Developed and optimized scalable data pipelines and backend systems in Python, applying modular design and OOP principles to deliver high-performance, maintainable ETL workflows.</li>
          <li>Enhanced development efficiency by leveraging PyCharm IDE, utilizing advanced refactoring tools and debugging features to improve code quality and maintainability.</li>
          <li>Implemented collaborative Git workflows, defining branching strategies, code review protocols and pull request pipelines to ensure clean, traceable and version-controlled data systems.</li>
          <li>Designed and deployed data-driven web services using Django, building RESTful APIs and custom middleware for secure integration with enterprise data platforms.</li>
          <li>Managed and optimized relational databases in SQLite, improving schema design and query performance for agile prototyping and lightweight data applications.</li>
          <li>Automated data collection and enrichment through custom web scraping pipelines built with Beautiful Soup, parsing structured and unstructured data for analytics-ready datasets.</li>
          <li>Strengthened data workflow reliability by implementing unit and integration testing with unittest, following TDD principles to ensure robustness and early error detection.</li>
          <li>Performed large-scale data wrangling, preprocessing and numerical analysis with NumPy, enabling feature engineering and model validation for machine learning pipelines.</li>
          <li>Built, trained and fine-tuned machine learning models using Scikit-learn, integrating classification, regression and clustering algorithms into production-grade ETL workflows.</li>
          <li>Automated distributed ETL and data processing tasks with Celery, enabling asynchronous execution, task scheduling and error-handling for improved pipeline scalability.</li>
          <li>Conducted exploratory data analysis and visualization in Jupyter Notebook, documenting workflows to improve collaboration between engineering and data science teams.</li>
        </ul>
      </div>
    </section>

    <!-- Education & Certificates -->
    <section class="section">
      <div class="section-title">Education</div>
      <p>Bachelor's Degree in Computer Science.</p>
    </section>

    <section class="section">
      <div class="section-title">Professional Certificates</div>
      <ul>
        <li>AWS Certified AI Practitioner Foundational.</li>
        <li>AWS Certified Machine Learning Engineer Associate.</li>
        <li>Microsoft Certified Azure AI Engineer Associate.</li>
      </ul>
    </section>
  </div>
</body>
</html>
